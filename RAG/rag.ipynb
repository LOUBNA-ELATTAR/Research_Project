{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12440302",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-20T12:03:51.691903Z",
          "iopub.status.busy": "2024-02-20T12:03:51.691194Z",
          "iopub.status.idle": "2024-02-20T12:04:19.836242Z",
          "shell.execute_reply": "2024-02-20T12:04:19.835259Z"
        },
        "papermill": {
          "duration": 28.152332,
          "end_time": "2024-02-20T12:04:19.838551",
          "exception": false,
          "start_time": "2024-02-20T12:03:51.686219",
          "status": "completed"
        },
        "tags": [],
        "id": "12440302",
        "outputId": "86e51c82-57ac-43a1-9daf-9fdd2ee7d4b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence_transformers\r\n",
            "  Obtaining dependency information for sentence_transformers from https://files.pythonhosted.org/packages/06/97/57afa3d05801b6b9305f96a7ce5995e12c1d2ba25ce66747de107816b0b5/sentence_transformers-2.3.1-py3-none-any.whl.metadata\r\n",
            "  Downloading sentence_transformers-2.3.1-py3-none-any.whl.metadata (11 kB)\r\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.36.2)\r\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.1)\r\n",
            "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.0.0)\r\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.24.3)\r\n",
            "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\r\n",
            "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\r\n",
            "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (3.2.4)\r\n",
            "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\r\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.20.2)\r\n",
            "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (9.5.0)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.12.2)\r\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.12.2)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.5.0)\r\n",
            "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (21.3)\r\n",
            "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\r\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1)\r\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.8.8)\r\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.0)\r\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.1)\r\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.16.0)\r\n",
            "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\r\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence_transformers) (3.0.9)\r\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\r\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.2.0)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.4)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.15)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2023.11.17)\r\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\r\n",
            "Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hInstalling collected packages: sentence_transformers\r\n",
            "Successfully installed sentence_transformers-2.3.1\r\n",
            "Collecting faiss-gpu\r\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\r\n",
            "Successfully installed faiss-gpu-1.7.2\r\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers\n",
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bc155f4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-20T12:04:19.854574Z",
          "iopub.status.busy": "2024-02-20T12:04:19.85392Z",
          "iopub.status.idle": "2024-02-20T12:04:42.229429Z",
          "shell.execute_reply": "2024-02-20T12:04:42.22831Z"
        },
        "papermill": {
          "duration": 22.385753,
          "end_time": "2024-02-20T12:04:42.231618",
          "exception": false,
          "start_time": "2024-02-20T12:04:19.845865",
          "status": "completed"
        },
        "tags": [],
        "id": "6bc155f4"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import logging\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer, LoggingHandler\n",
        "import faiss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32eaed2d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-20T12:04:42.247786Z",
          "iopub.status.busy": "2024-02-20T12:04:42.247196Z",
          "iopub.status.idle": "2024-02-20T12:47:26.375154Z",
          "shell.execute_reply": "2024-02-20T12:47:26.374129Z"
        },
        "papermill": {
          "duration": 2564.148438,
          "end_time": "2024-02-20T12:47:26.387109",
          "exception": false,
          "start_time": "2024-02-20T12:04:42.238671",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "6a8d65ff53ba432f875f3277668ce5f2",
            "c561464830b044ce9454eda6ad212609",
            "e10792bcc6f54d3784a4a38b97bade66",
            "7ddd289bb0944d37b7bc0340ef0812d6",
            "e7f2e0b11fde459fad8883bf8c40f307",
            "9932b604dac2453593cfe497aec05c8c",
            "acb8ac9b244644ac88ef6975287f12b8",
            "9ac7336931bc424197d2fec44d00fed5",
            "8e01d8f4eeb542c18a28012ca685a1ca",
            "f9d6dba7f828482bbe1fe17d53c334e0",
            "892a56d5131d473e98cd93f59b4809ab",
            "26728a52859c4e2f83969bf91952a566",
            "21e43cd5f688490db965727ec4a91184",
            "572e468d8c1244e09d48e51e8d3e4a82"
          ]
        },
        "id": "32eaed2d",
        "outputId": "a2af8cd5-c18f-4e67-9984-890aad7fd665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-0c393fc0da9c1b19/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a8d65ff53ba432f875f3277668ce5f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c561464830b044ce9454eda6ad212609",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-0c393fc0da9c1b19/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n",
            "The Wikipedia corpus contains 7871825 sentences.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e10792bcc6f54d3784a4a38b97bade66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ddd289bb0944d37b7bc0340ef0812d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7f2e0b11fde459fad8883bf8c40f307",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9932b604dac2453593cfe497aec05c8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acb8ac9b244644ac88ef6975287f12b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ac7336931bc424197d2fec44d00fed5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e01d8f4eeb542c18a28012ca685a1ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9d6dba7f828482bbe1fe17d53c334e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "892a56d5131d473e98cd93f59b4809ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26728a52859c4e2f83969bf91952a566",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21e43cd5f688490db965727ec4a91184",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The embedding dimension of the all-MiniLM-L6-v2 model is 384.\n",
            "Max sequence lenght of the all-MiniLM-L6-v2 model is 256.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "572e468d8c1244e09d48e51e8d3e4a82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question:\n",
            "What is the Carnot engine?\n",
            "Relevant Wikipedia article chunks:\n",
            "['He received the Wm.', 'W Network (often shortened to W) is a Canadian English language Category A specialty channel, owned by Corus Entertainment.', 'WNWS (1520 AM) is a radio station broadcasting a Soft Adult Contemporary format.', 'WWLW is owned and operated by West Virginia Radio Corporation.', 'WYOU Community Television, Inc (WYOU) is a nonprofit Public, educational, and government access (PEG) cable television station for the Madison, Wisconsin area.']\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    wiki_corpus_paths = '/kaggle/input/wikipedia-sentences/wikisent2.txt'\n",
        "    processed_wiki_dataset = load_dataset(\"text\", data_files={\"train\": wiki_corpus_paths}, split='train')\n",
        "    print(f'The Wikipedia corpus contains {len(processed_wiki_dataset)} sentences.')\n",
        "    model_name = \"all-MiniLM-L6-v2\"\n",
        "    model = SentenceTransformer(model_name)\n",
        "    embedding_dim = model.get_sentence_embedding_dimension()\n",
        "    max_seq_len = model.max_seq_length\n",
        "    print(f'The embedding dimension of the all-MiniLM-L6-v2 model is {embedding_dim}.')\n",
        "    print(f\"Max sequence lenght of the {model_name} model is {max_seq_len}.\")\n",
        "    M = 32\n",
        "    quantizer = faiss.IndexHNSWFlat(\n",
        "                        embedding_dim,\n",
        "                        M,\n",
        "                        faiss.METRIC_INNER_PRODUCT\n",
        "                        )\n",
        "    nlist = 10_000\n",
        "    nsegment = 16\n",
        "    nbit = 8\n",
        "    cpu_index = faiss.IndexIVFPQ(\n",
        "                        quantizer,\n",
        "                        embedding_dim,\n",
        "                        nlist, nsegment, nbit,\n",
        "                        faiss.METRIC_INNER_PRODUCT\n",
        "                        )\n",
        "\n",
        "    gpu_index = faiss.index_cpu_to_all_gpus(\n",
        "        cpu_index\n",
        "    )\n",
        "\n",
        "    pool = model.start_multi_process_pool()\n",
        "    batch_size = 2**19\n",
        "    total_batches = len(processed_wiki_dataset['text']) // batch_size + (0 if len(processed_wiki_dataset['text']) % batch_size == 0 else 1)\n",
        "    for i in tqdm(range(0, len(processed_wiki_dataset['text']), batch_size), total=total_batches, desc=\"Processing Batches\"):\n",
        "        batch_texts = processed_wiki_dataset['text'][i:i + batch_size]\n",
        "        batch_embeddings = model.encode_multi_process(\n",
        "                                    batch_texts,\n",
        "                                    pool,\n",
        "                                    normalize_embeddings=True\n",
        "                                    )\n",
        "        gpu_index.train(batch_embeddings)\n",
        "        gpu_index.add(batch_embeddings)\n",
        "        del batch_embeddings\n",
        "        gc.collect()\n",
        "    gpu_index.nprobe = 1_000\n",
        "\n",
        "    def search_wiki_articles(question):\n",
        "        question_embedding = model.encode_multi_process(\n",
        "                                    question,\n",
        "                                    pool,\n",
        "                                    normalize_embeddings=True\n",
        "                                    )\n",
        "        distances, indices = gpu_index.search(question_embedding, k=5)\n",
        "        return [processed_wiki_dataset['text'][i] for i in indices[0]]\n",
        "\n",
        "    questions = [\n",
        "        'What is the Carnot engine?',\n",
        "        'What is a virtual particle?',\n",
        "        'What is Lorentz symmetry or Lorentz invariance in relativistic physics?',\n",
        "        'What did Newton adopt after his correspondence with Hooke in 1679-1680?',\n",
        "        'What is the difference between redshift due to the expansion of the universe and Doppler redshift?',\n",
        "    ]\n",
        "\n",
        "    relevant_article_chunks = [search_wiki_articles(question) for question in questions]\n",
        "\n",
        "    print(f'Question:\\n{questions[0]}')\n",
        "    print(f'Relevant Wikipedia article chunks:\\n{relevant_article_chunks[0]}')\n",
        "\n",
        "    model.stop_multi_process_pool(pool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a1c5e6e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-20T12:47:26.428758Z",
          "iopub.status.busy": "2024-02-20T12:47:26.428446Z",
          "iopub.status.idle": "2024-02-20T12:47:31.397605Z",
          "shell.execute_reply": "2024-02-20T12:47:31.3966Z"
        },
        "papermill": {
          "duration": 4.982793,
          "end_time": "2024-02-20T12:47:31.400048",
          "exception": false,
          "start_time": "2024-02-20T12:47:26.417255",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "aeaf9776ecd64f878b471ad10d9de061",
            "c0da6ec65c594ee6ab558f1b2ef3bb62",
            "de27f47378e64871b891ef925bdcba32",
            "de5e2b64000347e2b1a4e3fafa5ddb1d",
            "11a9aab8ede141b8a7b243af3ab072d9"
          ]
        },
        "id": "6a1c5e6e",
        "outputId": "d59d5b3e-e57c-4bf7-a748-16832b9c11a5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aeaf9776ecd64f878b471ad10d9de061",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0da6ec65c594ee6ab558f1b2ef3bb62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de27f47378e64871b891ef925bdcba32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de5e2b64000347e2b1a4e3fafa5ddb1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11a9aab8ede141b8a7b243af3ab072d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The maximum length of tokens the we can feed to the tokenizer before truncation is 512.\n",
            "Question:\n",
            "What is the Carnot engine?\n",
            "Answer:\n",
            "'WNWS',\n",
            "score:0.0615, start:144, end:148\n",
            "==============================\n",
            "Question:\n",
            "What is a virtual particle?\n",
            "Answer:\n",
            "'Soft Adult Contemporary',\n",
            "score:0.5277, start:193, end:216\n",
            "==============================\n",
            "Question:\n",
            "What is Lorentz symmetry or Lorentz invariance in relativistic physics?\n",
            "Answer:\n",
            "'Soft Adult Contemporary',\n",
            "score:0.0478, start:193, end:216\n",
            "==============================\n",
            "Question:\n",
            "What did Newton adopt after his correspondence with Hooke in 1679-1680?\n",
            "Answer:\n",
            "'Wm. W Network',\n",
            "score:0.1945, start:16, end:29\n",
            "==============================\n",
            "Question:\n",
            "What is the difference between redshift due to the expansion of the universe and Doppler redshift?\n",
            "Answer:\n",
            "'Soft Adult Contemporary format',\n",
            "score:0.078, start:193, end:223\n",
            "==============================\n"
          ]
        }
      ],
      "source": [
        "qa_model_name = 'distilbert-base-cased-distilled-squad'\n",
        "question_answerer = pipeline('question-answering', model=qa_model_name, tokenizer=qa_model_name)\n",
        "print(f'The maximum length of tokens the we can feed to the tokenizer before truncation is {question_answerer.tokenizer.model_max_length}.')\n",
        "\n",
        "def answer_question(question, article_chunks):\n",
        "    context = ' '.join(article_chunks)\n",
        "    result = question_answerer(question=question, context=context)\n",
        "    return result\n",
        "\n",
        "results = [answer_question(questions[idx], relevant_article_chunks[idx]) for idx in range(len(questions))]\n",
        "\n",
        "for idx in range(len(questions)):\n",
        "    print(f'Question:\\n{questions[idx]}')\n",
        "    print(f\"Answer:\\n'{results[idx]['answer']}',\\nscore:{round(results[idx]['score'], 4)}, start:{results[idx]['start']}, end:{results[idx]['end']}\")\n",
        "    print('='*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f8322a1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-20T12:47:31.469358Z",
          "iopub.status.busy": "2024-02-20T12:47:31.468985Z",
          "iopub.status.idle": "2024-02-20T12:47:31.485211Z",
          "shell.execute_reply": "2024-02-20T12:47:31.484073Z"
        },
        "papermill": {
          "duration": 0.038754,
          "end_time": "2024-02-20T12:47:31.487799",
          "exception": false,
          "start_time": "2024-02-20T12:47:31.449045",
          "status": "completed"
        },
        "tags": [],
        "id": "4f8322a1"
      },
      "outputs": [],
      "source": [
        "\"\"\"Official evaluation script for SQuAD version 2.0.\n",
        "\n",
        "In addition to basic functionality, we also compute additional statistics and\n",
        "plot precision-recall curves if an additional na_prob.json file is provided.\n",
        "This file is expected to map question ID's to the model's predicted probability\n",
        "that a question is unanswerable.\n",
        "\"\"\"\n",
        "import argparse\n",
        "import collections\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import sys\n",
        "\n",
        "OPTS = None\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser('Official evaluation script for SQuAD version 2.0.')\n",
        "    parser.add_argument('data_file', metavar='data.json', help='Input data JSON file.')\n",
        "    parser.add_argument('pred_file', metavar='pred.json', help='Model predictions.')\n",
        "    parser.add_argument('--out-file', '-o', metavar='eval.json',\n",
        "                        help='Write accuracy metrics to file (default is stdout).')\n",
        "    parser.add_argument('--na-prob-file', '-n', metavar='na_prob.json',\n",
        "                        help='Model estimates of probability of no answer.')\n",
        "    parser.add_argument('--na-prob-thresh', '-t', type=float, default=1.0,\n",
        "                        help='Predict \"\" if no-answer probability exceeds this (default = 1.0).')\n",
        "    parser.add_argument('--out-image-dir', '-p', metavar='out_images', default=None,\n",
        "                        help='Save precision-recall curves to directory.')\n",
        "    parser.add_argument('--verbose', '-v', action='store_true')\n",
        "    if len(sys.argv) == 1:\n",
        "        parser.print_help()\n",
        "        sys.exit(1)\n",
        "    return parser.parse_args()\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
        "        return re.sub(regex, ' ', text)\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def get_tokens(s):\n",
        "    if not s:\n",
        "        return []\n",
        "    return normalize_answer(s).split()\n",
        "\n",
        "def compute_exact(a_gold, a_pred):\n",
        "    return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
        "\n",
        "def compute_f1(a_gold, a_pred):\n",
        "    gold_toks = get_tokens(a_gold)\n",
        "    pred_toks = get_tokens(a_pred)\n",
        "    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
        "    num_same = sum(common.values())\n",
        "    if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
        "        return int(gold_toks == pred_toks)\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(pred_toks)\n",
        "    recall = 1.0 * num_same / len(gold_toks)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e1a7479",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-20T12:47:31.525192Z",
          "iopub.status.busy": "2024-02-20T12:47:31.524813Z",
          "iopub.status.idle": "2024-02-20T12:47:51.56244Z",
          "shell.execute_reply": "2024-02-20T12:47:51.561373Z"
        },
        "papermill": {
          "duration": 20.060099,
          "end_time": "2024-02-20T12:47:51.564637",
          "exception": false,
          "start_time": "2024-02-20T12:47:31.504538",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "a720da9e5d7a4d83ba007f0908d2c1d0",
            "38fdd74b92364d9da31e052e976fc47c",
            "62dfe3a64f054f08ae853448f0fae371",
            "0b301bf3f9ef4cd0bcfeaec9b4a9edd0",
            "0dbad4b39f7f452a8d04f202556e26bc",
            "d72710c3ea0049149c086dfe4ea22b00",
            "d8c5c938e02640b28a548fa21c52cf07",
            "ca21baaff7a34a67993f4b5f5dc76c2c"
          ]
        },
        "id": "0e1a7479",
        "outputId": "6b96ec0e-b713-4ae0-baa5-d0770763dd2a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a720da9e5d7a4d83ba007f0908d2c1d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38fdd74b92364d9da31e052e976fc47c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset squad/plain_text (download: 33.51 MiB, generated: 85.63 MiB, post-processed: Unknown size, total: 119.14 MiB) to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62dfe3a64f054f08ae853448f0fae371",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b301bf3f9ef4cd0bcfeaec9b4a9edd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/8.12M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dbad4b39f7f452a8d04f202556e26bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d72710c3ea0049149c086dfe4ea22b00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8c5c938e02640b28a548fa21c52cf07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca21baaff7a34a67993f4b5f5dc76c2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset squad downloaded and prepared to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453. Subsequent calls will reuse this data.\n",
            "Question:\n",
            "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
            "Predited Answer:\n",
            "Saint Bernadette Soubirous\n",
            "Proper answer accoding to SQuAD:\n",
            "Saint Bernadette Soubirous\n",
            "F1: 1.0,\tE: 1\n"
          ]
        }
      ],
      "source": [
        "squad_dataset = dataset = load_dataset('squad', split='train')\n",
        "\n",
        "question = squad_dataset['question'][0]\n",
        "context = squad_dataset['context'][0]\n",
        "answer = squad_dataset['answers'][0]\n",
        "\n",
        "result = question_answerer(question=question, context=context)\n",
        "\n",
        "exact_score = compute_exact(a_gold=answer['text'][0], a_pred=result['answer'])\n",
        "f1_score = compute_f1(a_gold=answer['text'][0], a_pred=result['answer'])\n",
        "\n",
        "\n",
        "print(f'Question:\\n{question}')\n",
        "print(f\"Predited Answer:\\n{result['answer']}\")\n",
        "print(f\"Proper answer accoding to SQuAD:\\n{answer['text'][0]}\")\n",
        "print(f'F1: {f1_score},\\tE: {exact_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe6e1d9",
      "metadata": {
        "papermill": {
          "duration": 0.011927,
          "end_time": "2024-02-20T12:47:51.615466",
          "exception": false,
          "start_time": "2024-02-20T12:47:51.603539",
          "status": "completed"
        },
        "tags": [],
        "id": "9fe6e1d9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 46601,
          "sourceId": 84740,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4348765,
          "sourceId": 7470313,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30635,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 2646.480531,
      "end_time": "2024-02-20T12:47:54.560676",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-02-20T12:03:48.080145",
      "version": "2.4.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}